{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This implementation is from group 05, made by:\n",
    "\n",
    "- Joao Fonseca 89476\n",
    "- Tomas Lopes 89552\n",
    "\n",
    "\n",
    "This Notebook showcases the functional part of the second delivery. In each section we present the function and a set of outputs. After each function we will mention the structure and the meaning of each input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - clustering\n",
    "from clustering import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clusters: [(array([0., 0., 0., ..., 0., 0., 0.]), {197, 134, 102, 136, 180}), (array([0., 0., 0., ..., 0., 0., 0.]), {160, 170, 177, 187, 159}), (array([0., 0., 0., ..., 0., 0., 0.]), {174, 198, 158}), (array([0., 0., 0., ..., 0., 0., 0.]), {107, 125}), (array([0., 0., 0., ..., 0., 0., 0.]), {114, 110}), (array([0., 0., 0., ..., 0., 0., 0.]), {192, 111}), (array([0.06980858, 0.        , 0.        , ..., 0.06186659, 0.05997764,\n",
      "       0.33195777]), {148, 135}), (array([0., 0., 0., ..., 0., 0., 0.]), {141, 149}), (array([0.       , 0.       , 0.       , ..., 0.       , 0.0707719,\n",
      "       0.       ]), {105, 147}), (array([0.        , 0.        , 0.        , ..., 0.11700774, 0.        ,\n",
      "       0.        ]), {176, 162, 165}), (array([0., 0., 0., ..., 0., 0., 0.]), {156, 175}), (array([0., 0., 0., ..., 0., 0., 0.]), {145, 143}), (array([0., 0., 0., ..., 0., 0., 0.]), {112, 106}), (array([0.        , 0.12061111, 0.        , ..., 0.        , 0.        ,\n",
      "       0.        ]), {104, 131}), (array([0., 0., 0., ..., 0., 0., 0.]), {128, 115}), (array([0., 0., 0., ..., 0., 0., 0.]), {121, 126}), (array([0., 0., 0., ..., 0., 0., 0.]), {154, 171}), (array([0., 0., 0., ..., 0., 0., 0.]), {184, 178}), (array([0., 0., 0., ..., 0., 0., 0.]), {193, 199, 119, 189, 191}), (array([0., 0., 0., ..., 0., 0., 0.]), {139, 117, 133}), (array([0., 0., 0., ..., 0., 0., 0.]), {173, 151}), (array([0., 0., 0., ..., 0., 0., 0.]), {188, 157}), (array([0., 0., 0., ..., 0., 0., 0.]), {200, 181}), (array([0., 0., 0., ..., 0., 0., 0.]), {185, 169, 186, 163}), (array([0., 0., 0., ..., 0., 0., 0.]), {138}), (array([0., 0., 0., ..., 0., 0., 0.]), {146}), (array([0., 0., 0., ..., 0., 0., 0.]), {196, 172}), (array([0., 0., 0., ..., 0., 0., 0.]), {195}), (array([0., 0., 0., ..., 0., 0., 0.]), {168, 153, 167}), (array([0., 0., 0., ..., 0., 0., 0.]), {120, 137, 132, 144}), (array([0.        , 0.        , 0.32023668, ..., 0.        , 0.        ,\n",
      "       0.        ]), {164, 124}), (array([0., 0., 0., ..., 0., 0., 0.]), {179, 190}), (array([0., 0., 0., ..., 0., 0., 0.]), {123}), (array([0., 0., 0., ..., 0., 0., 0.]), {150}), (array([0.        , 0.        , 0.        , ..., 0.11966038, 0.        ,\n",
      "       0.        ]), {142}), (array([0., 0., 0., ..., 0., 0., 0.]), {152, 182, 166}), (array([0., 0., 0., ..., 0., 0., 0.]), {161, 194}), (array([0., 0., 0., ..., 0., 0., 0.]), {155, 183}), (array([0., 0., 0., ..., 0., 0., 0.]), {130}), (array([0.        , 0.        , 0.        , ..., 0.17688366, 0.        ,\n",
      "       0.        ]), {116}), (array([0., 0., 0., ..., 0., 0., 0.]), {118}), (array([0.        , 0.        , 0.        , ..., 0.        , 0.20753233,\n",
      "       0.        ]), {101}), (array([0., 0., 0., ..., 0., 0., 0.]), {127}), (array([0., 0., 0., ..., 0., 0., 0.]), {113}), (array([0.        , 0.        , 0.        , ..., 0.12125004, 0.        ,\n",
      "       0.        ]), {140}), (array([0., 0., 0., ..., 0., 0., 0.]), {129}), (array([0.        , 0.        , 0.        , ..., 0.12153874, 0.        ,\n",
      "       0.        ]), {103}), (array([0., 0., 0., ..., 0., 0., 0.]), {108}), (array([0., 0., 0., ..., 0., 0., 0.]), {109}), (array([0., 0., 0., ..., 0., 0., 0.]), {122})]\n"
     ]
    }
   ],
   "source": [
    "# Clustering Approach (a) - clustering\n",
    "\n",
    "# Processing the topics corpus (stop words removal, stemming, tag removal, selection of pertinent sections)\n",
    "corpus = process_topics(topic_directory)\n",
    "\n",
    "# Clustering the corpus (with n_clusters=50)\n",
    "clusters = clustering(corpus, clustering_model=AgglomerativeClustering(n_clusters=50, linkage=\"complete\", affinity=\"cosine\"))\n",
    "\n",
    "print(f\"Clusters: {clusters}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we clustered the entire topic collection.\n",
    "\n",
    "__@input:__\n",
    "\n",
    "__corpus__ corresponds to the processed topic/document collection\n",
    "\n",
    "__clustering_model__ corresponds to the clustering model to be used\n",
    "\n",
    "__@output__\n",
    "\n",
    "A list of tuples, where each of them corresponds to a cluster - a pair composed by its centroid and a set of topic/document identifiers in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of docs in cluster 0: 5\n",
      "Docs in cluster 0: [102, 134, 136, 180, 197]\n",
      "Cluster 0 centroid: [0. 0. 0. ... 0. 0. 0.]\n",
      "Cluster 0 medoid: 197\n",
      "Suggested label for cluster 0: crime crimin law\n",
      "Geometric median of cluster 0: [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Clustering Approach (b) - interpret\n",
    "\n",
    "# Describes the documents in the first cluster (considering median and medoid criteria)\n",
    "n_docs, docs_in_cluster, centroid, medoid, label, median = interpret(clusters[0], corpus)\n",
    "\n",
    "print(f\"Number of docs in cluster 0: {n_docs}\")\n",
    "print(f\"Docs in cluster 0: {docs_in_cluster}\")\n",
    "print(f\"Cluster 0 centroid: {centroid}\")\n",
    "print(f\"Cluster 0 medoid: {medoid}\")\n",
    "print(f\"Suggested label for cluster 0: {label}\")\n",
    "print(f\"Geometric median of cluster 0: {median}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we interpreted the first cluster of the list of clusters returned in the previous cell.\n",
    "\n",
    "__@input:__\n",
    "\n",
    "__cluster__ corresponds to the cluster which is going to be analyzed\n",
    "\n",
    "__corpus__ corresponds to the processed topic/document collection\n",
    "\n",
    "__@output__\n",
    "\n",
    "The number of topics/documents in the cluster and their identifiers, the centroid and medoid of the cluster, the suggested label for the cluster given the corpus and its geometric median (through unconstrained minimization, using the BFGS method with cosine distance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette coefficient: 0.19126574065915034\n",
      "Variance Ratio Criterion: 2.1279172493520955\n",
      "Davies-Bouldin index: 1.0913503208711628\n"
     ]
    }
   ],
   "source": [
    "# Clustering Approach (c) - evaluate\n",
    "\n",
    "# Evaluates the solution produced by the clustering function\n",
    "sil_score, vrc, dbi = evaluate(corpus, clustering_model=AgglomerativeClustering(n_clusters=50, linkage=\"complete\", affinity=\"cosine\"))\n",
    "\n",
    "print(f\"Silhouette coefficient: {sil_score}\")\n",
    "print(f\"Variance Ratio Criterion: {vrc}\")\n",
    "print(f\"Davies-Bouldin index: {dbi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we evaluated the clustering approach we had selected (AgglomerativeClustering with 50 clusters, complete linkage and cosine affinity).\n",
    "\n",
    "__@input:__\n",
    "\n",
    "__corpus__ corresponds to the processed topic/document collection\n",
    "\n",
    "__clustering_model__ corresponds to the clustering model to be used\n",
    "\n",
    "__@output__\n",
    "\n",
    "The silhouette coefficient, the variance ratio criterion and the Davies-Bouldin index of the selected clustering approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - classification\n",
    "from classification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Supervised Approach - setting up\n",
    "\n",
    "# Process documents for the training and testing corpus (stop words removal, stemming, tag removal, selection of pertinent sections)\n",
    "train_corpus = process_documents(corpus_directory, train=True)\n",
    "test_corpus = process_documents(corpus_directory, train=False)\n",
    "\n",
    "# Extract the relevance feedback for the training and testing process\n",
    "train_rels = extract_relevance(qrels_train_directory)\n",
    "test_rels = extract_relevance(qrels_test_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(metric='euclidean', n_neighbors=25)\n"
     ]
    }
   ],
   "source": [
    "# Supervised Approach (a) - training\n",
    "\n",
    "# Processes topic R135 (stop words removal, stemming, tag removal, selection of pertinent sections)\n",
    "topic = process_topic(135, topic_directory)\n",
    "\n",
    "# The classifier used was K-Nearest-Neighbours with n_neighbours=15 and metric=\"euclidean\"\n",
    "classification_model = KNeighborsClassifier(n_neighbors=25, metric=\"euclidean\")\n",
    "\n",
    "# Trains the classification model with the documents that have relevance feedback for topics [R104, R135, R175],\n",
    "# using features from topic 135\n",
    "model = training(topic, train_corpus, train_rels, model=classification_model)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we trained the classification model with documents and relevance feedback regarding topics R104, R135 and R175, and with features calculated using the processed content of topic R135.\n",
    "The classifier used was K-Nearest-Neighbours with n_neighbours=15 and metric=\"euclidean\".\n",
    "\n",
    "__@input:__\n",
    "\n",
    "__topic__ corresponds to the processed topic content\n",
    "\n",
    "__d_train__ corresponds to the processed training corpus\n",
    "\n",
    "__r_train__ corresponds to the relevance feedback for the Dtrain collection\n",
    "\n",
    "__model__ corresponds to the classifier used for this approach\n",
    "\n",
    "__@output__\n",
    "\n",
    "The fitted classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.56, 0.0, 0.56, 0.36, 0.0, 0.0, 0.36, 0.56, 0.0, 0.0, 0.36, 0.0, 0.0, 0.48, 0.0, 0.56, 0.56, 0.48, 0.48, 0.56, 0.48, 0.0, 0.0, 0.36, 0.32, 0.0, 0.36, 0.0, 0.36, 0.28, 0.32, 0.0, 0.28, 0.28, 0.32, 0.56, 0.56, 0.28, 0.44, 0.56, 0.48, 0.56, 0.44, 0.36, 0.56, 0.0, 0.36, 0.56, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28, 0.56, 0.0, 0.0, 0.56, 0.28, 0.0, 0.0, 0.56, 0.56, 0.36, 0.0, 0.0, 0.36, 0.36, 0.28, 0.56, 0.36, 0.28, 0.56, 0.28, 0.36, 0.0, 0.0, 0.36, 0.0, 0.48, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.48, 0.0, 0.0, 0.0, 0.04, 0.48, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.48, 0.4, 0.56, 0.56, 0.0, 0.0, 0.0, 0.0, 0.56, 0.56, 0.56, 0.0, 0.0, 0.48, 0.56, 0.0, 0.56, 0.56, 0.56, 0.0, 0.56, 0.56, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.32, 0.48, 0.0, 0.0, 0.0, 0.0, 0.56, 0.56, 0.56, 0.56, 0.0, 0.56, 0.0, 0.0, 0.0, 0.56, 0.36, 0.0, 0.56, 0.0, 0.56, 0.0, 0.56, 0.0, 0.36, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.56, 0.56, 0.0, 0.0, 0.56, 0.0, 0.56, 0.0, 0.28, 0.36, 0.0, 0.0, 0.0, 0.0, 0.36, 0.36, 0.0, 0.56, 0.0, 0.0, 0.56, 0.56, 0.0, 0.0, 0.0, 0.56, 0.56, 0.56, 0.56, 0.0, 0.48, 0.56, 0.0, 0.28, 0.36, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.56, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.56, 0.56, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.28, 0.28, 0.56, 0.36, 0.0, 0.56, 0.0, 0.56, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.56, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.36, 0.36, 0.56, 0.0, 0.56, 0.56, 0.56, 0.0, 0.56, 0.0, 0.56, 0.56, 0.56, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.56, 0.56, 0.56, 0.56, 0.56, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.56, 0.36, 0.56, 0.56, 0.56, 0.56, 0.0, 0.56, 0.56, 0.0, 0.56, 0.56, 0.0, 0.0, 0.0, 0.56, 0.56, 0.56, 0.0, 0.56, 0.0, 0.0, 0.56, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.48, 0.56, 0.56, 0.56, 0.56, 0.44, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.56, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.56, 0.0, 0.0, 0.56, 0.56, 0.0, 0.0, 0.0, 0.48, 0.48, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "# Supervised Approach (b) - classify\n",
    "\n",
    "classes = [classify(test_corpus[i][1], topic, model) for i in range(len(test_corpus))]\n",
    "\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we classified each document in the test corpus according to the what the model learned.\n",
    "\n",
    "__@input:__\n",
    "\n",
    "__doc__ corresponds to the document to be classified by the model\n",
    "\n",
    "__topic__ corresponds to the processed content of the topic, for which the model will give a probabilistic output on the relevance of the given document\n",
    "\n",
    "__model__ corresponds to the trained classifier\n",
    "\n",
    "__@output__\n",
    "\n",
    "The probabilistic output on the relevance of the given document to the given topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating topic 135\n",
      "***Statistics for topic R135***\n",
      "**With the original continuous probability values (using regression metrics)**\n",
      "\n",
      "Mean squared error: 0.1046464\n",
      "Mean absolute error: 0.19424\n",
      "Explained variance score: 0.5681060817093302\n",
      "R^2 score: 0.5035655325527997\n",
      "\n",
      "**With binarization of probability values (p >= 0.3 is considered relevant, else irrelevant)**\n",
      "\n",
      "True positives: 138\n",
      "False negatives: 13\n",
      "False positives: 35\n",
      "True negatives: 314\n",
      "Accuracy score: 0.904\n",
      "Sensitivity: 0.9139072847682119\n",
      "Specificity: 0.8997134670487106\n"
     ]
    }
   ],
   "source": [
    "# Supervised Approach (c) - evaluate\n",
    "\n",
    "evaluation = evaluate([135], test_corpus, test_rels, [classes])\n",
    "\n",
    "print(f\"***Statistics for topic R135***\")\n",
    "mse, mae, evs, r2, tp, fn, fp, tn, acc, sens, spec = evaluation[0]\n",
    "print(\"**With the original continuous probability values (using regression metrics)**\")\n",
    "print()\n",
    "print(f\"Mean squared error: {mse}\")\n",
    "print(f\"Mean absolute error: {mae}\")\n",
    "print(f\"Explained variance score: {evs}\")\n",
    "print(f\"R^2 score: {r2}\")\n",
    "print()\n",
    "print(f\"**With binarization of probability values (p >= {bin_prob_threshold} is considered relevant, else irrelevant)**\")\n",
    "print()\n",
    "print(f\"True positives: {tp}\")\n",
    "print(f\"False negatives: {fn}\")\n",
    "print(f\"False positives: {fp}\")\n",
    "print(f\"True negatives: {tn}\")\n",
    "print(f\"Accuracy score: {acc}\")\n",
    "print(f\"Sensitivity: {sens}\")\n",
    "print(f\"Specificity: {spec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we evaluated the output of the classification approach we had selected, using a probability threshold of 0.3 (probability values greater than or equal to this threshold will be regarded as relevant for computation of classification metrics)\n",
    "\n",
    "__@input:__\n",
    "\n",
    "__topics__ corresponds to the identifiers of the topics used in the training procedure\n",
    "\n",
    "__d_test__ corresponds to the processed testing corpus\n",
    "\n",
    "__r_test__ corresponds to the relevance feedback for the Dtest collection\n",
    "\n",
    "__classes_list__ corresponds to the list of previously calculated probabilities on the relevance of the documents\n",
    "\n",
    "__@output__\n",
    "\n",
    "The mean squared error, mean absolute error, explained variance score, and R^2 score of the classification output (regression metrics), as well as the confusion matrix, accuracy score, sensitivity, and specificity (classification metrics)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports - graph ranking\n",
    "from pagerank import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graph Ranking Approach - setting up\n",
    "\n",
    "# Process documents and topics (stop words removal, stemming, tag removal, selection of pertinent sections)\n",
    "corpus = process_documents(corpus_directory, stemmed=True, train=False)\n",
    "topics = process_topics(topic_directory, stemmed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 20 Nodes:\n",
      "[86971, 87911, 88903, 88908, 88914, 88993, 89021, 89133, 89439, 89726, 89905, 89987, 91489, 91543, 91659, 91966, 92158, 92447, 92516, 92593]\n",
      "First 20 Edges:\n",
      "[(86971, 101496), (86971, 115834), (86971, 132311), (86971, 149293), (86971, 165346), (86971, 181714), (86971, 181893), (86971, 198798), (86971, 216162), (86971, 230195), (86971, 274492), (86971, 281402), (86971, 290055), (88903, 88993), (88903, 89905), (88903, 91543), (88903, 102895), (88903, 103512), (88903, 105574), (88903, 106284)]\n"
     ]
    }
   ],
   "source": [
    "# Graph Ranking Approach (a) - build graph\n",
    "\n",
    "# Construct the graph that reflects document relationships\n",
    "graph = build_graph(corpus, use_idf=True, threshold=0.4)\n",
    "\n",
    "# Get the nodes and edges of the graph\n",
    "nodes = list(graph.nodes)\n",
    "edges = list(graph.edges)\n",
    "\n",
    "print(\"First 20 Nodes:\")\n",
    "print(nodes[:20])\n",
    "print(\"First 20 Edges:\")\n",
    "print(edges[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__@input:__\n",
    "\n",
    "__corpus__ corresponds to the processed documents content\n",
    "\n",
    "__use_idf__ corresponds to whether the TF-IDF vectorizer will use IDF to obtain document similarities or not\n",
    "\n",
    "__threshold__ corresponds to the value of theta (minimum similarity threshold)\n",
    "\n",
    "__@output__\n",
    "\n",
    "An undirected graph that captures document relationships based on their similarities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 PageRank docs:\n",
      "[(115834, 0.05262626913048876), (149293, 0.05160712691763864), (132311, 0.051569304340374975), (165346, 0.04645318796295266), (181893, 0.04601172198864406), (181714, 0.04577070763277186), (198798, 0.0453270234053804), (216162, 0.0382565070915663), (230195, 0.03630450053135198), (101496, 0.03004616379067409), (274492, 0.024873846342984757), (281402, 0.024845811461217893), (290055, 0.02471151893781811), (86971, 0.019467718235574773), (181687, 0.012741160355552096), (183845, 0.012741160355552096), (102965, 0.009073035613730683), (103671, 0.009073035613730683), (181612, 0.008688010758045435), (181880, 0.008688010758045435)]\n"
     ]
    }
   ],
   "source": [
    "# Graph Ranking Approach (b) - undirected page rank\n",
    "\n",
    "# Calculates the PageRank for a set of documents\n",
    "upr = undirected_page_rank(topics[3], corpus, n_docs=20, threshold=0.9, sim=\"TF-IDF\", use_priors=True, weighted=True)\n",
    "    \n",
    "print(\"Top 20 PageRank docs:\")\n",
    "print(upr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we calculated the PageRank for a set of documents. The calculation of the priors was done based on the ranking scores for topic R104.\n",
    "The function did not use the previously built graph, as the build_graph function is called inside this one. The previous call was purely for demonstration purposes.\n",
    "\n",
    "__@input:__\n",
    "\n",
    "__topic__ corresponds to the processed topic content, used for calculation of prior probabilities\n",
    "\n",
    "__corpus__ corresponds to the processed documents content\n",
    "\n",
    "__n_docs__ corresponds to the number of top documents to return\n",
    "\n",
    "__sim__ corresponds to the similarity criterion that should be used to compare documents\n",
    "\n",
    "__threshold__ corresponds to the minimum similarity value for which documents are considered similar\n",
    "\n",
    "__max_iter__ corresponds to the maximum number of iterations the PageRank algorithm will perform\n",
    "\n",
    "__damping__ corresponds to the damping factor\n",
    "\n",
    "__use_priors__ corresponds to the whether the PageRank will account for prior probabilities or simply use a uniform distribution\n",
    "\n",
    "__weighted__ corresponds to the whether the PageRank algorithm will use weighted edges or simply uniformly distributed weights\n",
    "\n",
    "__@output__\n",
    "\n",
    "Ordered list of documents, in a descending order of score. They are presented in pairs of (document identifier, score)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}